\documentclass[12pt]{article}

\topmargin -40pt
\marginparwidth 0pt
 \oddsidemargin  -40pt
 \evensidemargin 0pt
 \marginparsep 0pt
\textwidth 7.2 in
 \textheight  10 in
 \hoffset  0.1in

\usepackage{amsthm,amsmath,amssymb,amscd,verbatim,epsfig}
\usepackage{mathptmx}
\usepackage{amsfonts}
%\usepackage{setapace}
\usepackage{graphicx}
\usepackage{bm}
%\usepackage{CJK}
\usepackage{ulem}
\usepackage{multicol}
\usepackage{enumerate}

\usepackage{fontspec}
\usepackage{xeCJK}
\setmainfont{Times New Roman}
\setCJKmainfont{TaipeiSansTCBeta-Regular}
\XeTeXlinebreaklocale "zh"
\XeTeXlinebreakskip = 0pt plus 1pt



\title{Homework 3 of Introduction to Analysis (I), Honor Class}
\author{AM15 黃琦翔 111652028}

\date{2023/9/26}

\begin{document}
\maketitle
\begin{enumerate}
    \item \begin{enumerate}
        \item[($d_1$)] \begin{enumerate}[a.]
            \item positive definite: $d(x, y) = (x-y)^2 \geq 0$ for any $x, y\in \mathbb{R}$ check
            \item 0 $\iff$ equal:\begin{enumerate}
                \item[($\implies$)] $d(x, y) = 0 \implies x - y = 0\implies x = y$
                \item[($\impliedby$)] $d(x, y) = (x-y)^2 = 0^2 = 0$ check
            \end{enumerate}
            \item triangle inequality: $4 = (2 - 0)^2 = d(2, 0) > 1 + 1 = d(2, 1) + d(1, 0)$ no
        \end{enumerate}
        Thus, $d_1$ is not a metric.
        
        \item[($d_2$)] \begin{enumerate}[a.]
            \item positive definite: since $| x-y| \geq 0$, then $\dfrac{|x-y|}{1+|x-y|} \geq 0$ check
            \item 0 $\iff$ equal:\begin{enumerate}
                \item[($\implies$)] since $0 = d(x, y) = \dfrac{0}{1+0}\implies x-y = 0\implies x = y$
                \item[($\impliedby$)] since $x = y$, $d(x, y) = \dfrac{0}{1 + 0} = 0$ check
            \end{enumerate}
            \item triangle inequality: If $z$ is not in $(x, y)$, the triangle inequality trivially holds.
            
            Then, WLOG, suppose $x < z < y$, then 
            
            $\dfrac{z-x}{1 + z - x} + \dfrac{y-z}{1 + y - z} > \dfrac{z-x}{1 + (z-x) + (y-z)} + \dfrac{y-z}{1 + (y-z) + (z-x)}\\ = \dfrac{y-x}{1 + (y-z) + (z-x)} = \dfrac{y-x}{1 + y -x}$
        \end{enumerate}
        Thus, $d_2$ is a metric.
    \end{enumerate}

    \item We want to prove $s_{n+1} - s_n < \epsilon$ for all $\epsilon > 0$ which means $x_n \to 0$.
    \begin{quote}
        Since $\displaystyle\limsup_{n \to \infty} \dfrac{x_{n+1}}{x_n} < 1$, 
        there exists some $N\in \mathbb{N}$ s.t. $\dfrac{x_{n+1}}{x_n} < 1$ for all $n > N$.

        Thus, $\lbrace x_n\rbrace_{n = N}^\infty$ is a monotone decreasing sequence bounded below by $0$.

        For any $r < 1$, $\dfrac{1}{r} > 1$ and there exists some $k \in \mathbb{N}$ s.t. $(\dfrac{1}{r})^k > n$ for all $n\in \mathbb{N}$,
        then $r^k < \dfrac{1}{n}$. Therefore, $1-r < 1\implies (1-r)^k \to 0$ for $k \to \infty$
        
        Since $(0, 1)$ is open, we can find some $r$ s.t.  $\dfrac{x_{n+1}}{x_n} < r < 1$ for all $n > N$. 
        Then, $\displaystyle\lim_{n \to \infty} x_n - x_{n+1} = \displaystyle\lim_{n\to \infty} x_n(1-\dfrac{x_{n+1}}{x_n}) < \lim x_N (1 - r)^{n-N} = 0$.

        Thus, $s_n$ is Cauchy$\implies s_n$ is convergence.
    \end{quote}

    \newpage
    \item \begin{enumerate}[(a)]
        \item WLOG, suppose $\lbrace x_n \rbrace$ is monotone increasing.
        
        Then, $\sigma_{n+1} - \sigma_n = (\dfrac{n}{n+1} S_n + \dfrac{x_{n+1}}{n+1}) - S_n = \dfrac{x_{n+1}}{n+1} - \dfrac{S_n}{n+1} > \dfrac{x_{n+1}-x_n}{n+1} > 0$ for all $n$.
        Therefore, $\sigma_n$ is monotone.

        \item we divided this question into $\lbrace x_n\rbrace$ diverges or bdd.
        
        \begin{enumerate}
            \item[(diverges)] WLOG, suppose $\limsup x_n = \infty$, then for any $M\in \mathbb{N}$, exists $N \in \mathbb{N}$ s.t. $x_n > M$ for $n \geq N$.
            
            Thus, there exists $M_1, N_1 \in \mathbb{N}$ s.t. $x_n \geq M_1$ for all $n \geq N_1$ and $\sigma_{N_1} > \dfrac{M\times N_1}{N_1} = M$.

            which means for any $M \in \mathbb{N}$, there exists some $N_1 \in \mathbb{N}$ s.t. $\sigma_n > M$ for all $n \geq N_1$.

            That means, $\lim \sigma_n = \lim x_n = \infty$.

            The case of diverging to $-\infty$ is the same.

            \item[(bounded)] First, we how it works in a subsequence converging to a cluster point.
            
            Let $\lbrace x_{n_k}\rbrace$ be a sequence converge to $a$ and $\mu_{k} = \dfrac{x_{n_1} + x_{n_2} + \cdots + x_{n_k}}{k}$, then for $\epsilon > 0$, there exists $N\in \mathbb{N}$ s.t. $|x_{n_k} - a| < \epsilon$ for all $k > N$.
            Thus, there exists some $\epsilon_1< \epsilon, N_1\in \mathbb{N}$ s.t. $|\mu_k - a| \leq \dfrac{|x_{n_1} - a| + \cdots + |x_{n_k} - a|}{k} < \dfrac{N\times \mu_N + \epsilon_1\times (k-N)}{k} < \epsilon$.
            Which means $\mu_k$ converge to $a$.

            And since $\dfrac{n_1 a_1 + n_2 a_2 + \cdots + n_k a_k}{n_1 + \cdots + n_k} < \displaystyle\max_{i\in [1, k]}(a_i)$ for all $n_i, k\in \mathbb{N}$ and $a_i \in \mathbb{R}$.

            Thus, if there are cluster points of $\lbrace x_n\rbrace$ named as $a_1, a_2, \cdots a_k$, we can say that $\limsup \sigma_n \leq \max a_n = \limsup x_n$.
        \end{enumerate}
        
        Then, $\limsup \sigma_n \leq \limsup x_n$ for all cases.
    \end{enumerate}
\end{enumerate}
\end{document}
